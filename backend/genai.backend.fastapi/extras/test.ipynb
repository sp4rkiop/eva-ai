{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, getpass\n",
    "from os import getenv\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import ConfigurableFieldSpec\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not getenv(\"AZURE_OPENAI_API_KEY\"):\n",
    "  os.environ[\"AZURE_OPENAI_API_KEY\"] = getpass.getpass(\"Enter API key for Azure: \")\n",
    "endpoint = getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "# endpoint = getenv(\"AZURE_OPENAI_ENDPOINT\").format(getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME\"),  getenv(\"AZURE_OPENAI_API_VERSION\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt = ChatPromptTemplate.from_template(\"Tell me a joke about {word} in 100 words.\")\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful translator. Translate the user sentence to French.\",\n",
    "        ),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "parser = StrOutputParser()\n",
    "llm = AzureChatOpenAI(\n",
    "    azure_endpoint=getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    azure_deployment=os.environ[\"AZURE_OPENAI_DEPLOYMENT_NAME\"],\n",
    "    api_version=os.environ[\"AZURE_OPENAI_API_VERSION\"],\n",
    "    temperature=0.01,\n",
    "    stream_usage=True\n",
    ")\n",
    "\n",
    "chain = prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [  \n",
    "(  \n",
    "\"system\",  \n",
    "\"You are a helpful translator. Translate the user sentence to French.\",  \n",
    "),  \n",
    "(\"human\", \"I love programming.\"),  \n",
    "] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await llm.ainvoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the full response at once\n",
    "if chain:\n",
    "    response = await chain.ainvoke({\"input\": \"story on earth\"})\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stream the response\n",
    "full_message = None\n",
    "\n",
    "async for chunk in chain.astream({\"input\": \"on earth\"}):\n",
    "    # print(chunk.content, end=\"\", flush=True)\n",
    "    if full_message is None:\n",
    "        full_message = chunk\n",
    "    else:\n",
    "        full_message += chunk  # Uses the overloaded __add__ method\n",
    "\n",
    "# After streaming is complete, full_message contains the aggregated content and metadata\n",
    "print(full_message)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(full_message))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Chat history in memory with proxy history upto last 2 messages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Sequence\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.messages import BaseMessage\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class InMemoryHistory(BaseChatMessageHistory, BaseModel):\n",
    "    messages: list[BaseMessage] = Field(default_factory=list)\n",
    "\n",
    "    def add_messages(self, messages: Sequence[BaseMessage]) -> None:\n",
    "        self.messages.extend(messages)\n",
    "\n",
    "    def clear(self) -> None:\n",
    "        self.messages = []\n",
    "\n",
    "class ProxyHistory(BaseChatMessageHistory):\n",
    "    def __init__(self, full_history: InMemoryHistory, limit: int = 2):\n",
    "        self._full_history = full_history\n",
    "        self._limit = limit\n",
    "\n",
    "    @property\n",
    "    def messages(self) -> Sequence[BaseMessage]: # type: ignore\n",
    "        # Only return the last N messages\n",
    "        return self._full_history.messages[-self._limit:]\n",
    "\n",
    "    def add_messages(self, messages: Sequence[BaseMessage]) -> None:\n",
    "        # Delegate writes to the original history\n",
    "        self._full_history.add_messages(messages)\n",
    "\n",
    "    def clear(self) -> None:\n",
    "        self._full_history.clear()\n",
    "\n",
    "\n",
    "store = {}\n",
    "session_id = \"student1234\"\n",
    "\n",
    "def get_by_session_id(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = InMemoryHistory()\n",
    "    return ProxyHistory(store[session_id], limit=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "import datetime\n",
    "@tool\n",
    "def current_time(input: str) -> str:\n",
    "    \"\"\"\n",
    "    Get the current date and time\n",
    "    \"\"\"\n",
    "    return \"The current time is: 2001-01-01 00:00:00\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt = ChatPromptTemplate.from_template(\"Tell me a joke about {word} in 100 words.\")\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", os.environ[\"SYSTEM_PROMPT\"]),\n",
    "    MessagesPlaceholder(variable_name=\"history\"),\n",
    "    (\"human\", \"{input}\"),\n",
    "])\n",
    "parser = StrOutputParser()\n",
    "llm = AzureChatOpenAI(\n",
    "    azure_endpoint=os.environ[\"AZURE_OPENAI_ENDPOINT\"],\n",
    "    azure_deployment=os.environ[\"AZURE_OPENAI_DEPLOYMENT_NAME\"],\n",
    "    api_version=os.environ[\"AZURE_OPENAI_API_VERSION\"],\n",
    "    temperature=0.01,\n",
    "    stream_usage=True\n",
    ")\n",
    "\n",
    "chain = prompt | llm\n",
    "chain_with_history = RunnableWithMessageHistory(\n",
    "    chain, # type: ignore\n",
    "    get_session_history=get_by_session_id,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"history\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async for chunk in chain_with_history.astream({\"input\": \"wow\"},\n",
    "    config={\"configurable\": {\"session_id\": \"base\"}}):\n",
    "    print(chunk, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(store)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Chat history with Scylla DB**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create keyspace and tables\n",
    "from cassandra.cluster import Cluster\n",
    "from cassandra.auth import PlainTextAuthProvider\n",
    "\n",
    "# Connect to ScyllaDB\n",
    "cluster = Cluster(['127.0.0.1'])  # Replace with your Scylla host IP if different\n",
    "session = cluster.connect()\n",
    "\n",
    "# Create keyspace (if not exists)\n",
    "KEYSPACE = \"eva\"\n",
    "session.execute(f\"\"\"\n",
    "    CREATE KEYSPACE IF NOT EXISTS {KEYSPACE}\n",
    "    WITH replication = {{'class': 'SimpleStrategy', 'replication_factor': '1'}}\n",
    "\"\"\")\n",
    "\n",
    "# Set keyspace\n",
    "session.set_keyspace(KEYSPACE)\n",
    "\n",
    "# Create tables\n",
    "table_queries = [\n",
    "    \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS chathistory (\n",
    "        userid uuid,\n",
    "        chatid uuid,\n",
    "        visible boolean,\n",
    "        chathistoryjson blob,\n",
    "        chattitle text,\n",
    "        createdon timestamp,\n",
    "        nettokenconsumption int,\n",
    "        PRIMARY KEY (userid, chatid)\n",
    "    );\n",
    "    \"\"\",\n",
    "    \"\"\"\n",
    "    CREATE MATERIALIZED VIEW IF NOT EXISTS chathistory_by_visible AS\n",
    "    SELECT userid, chatid, chathistoryjson, chattitle, createdon, nettokenconsumption\n",
    "    FROM chathistory\n",
    "    WHERE visible IS NOT NULL AND userid IS NOT NULL AND chatid IS NOT NULL\n",
    "    PRIMARY KEY (visible, userid, chatid);\n",
    "    \"\"\",\n",
    "    \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS availablemodels (\n",
    "        deploymentid uuid,\n",
    "        isactive boolean,\n",
    "        apikey text,\n",
    "        deploymentname text,\n",
    "        endpoint text,\n",
    "        modelname text,\n",
    "        modeltype text,\n",
    "        modelversion text,\n",
    "        provider text,\n",
    "        PRIMARY KEY ((deploymentid), isactive)\n",
    "    );\n",
    "    \"\"\",\n",
    "    \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS usersubscriptions (\n",
    "        userid uuid,\n",
    "        modelid uuid,\n",
    "        PRIMARY KEY (userid, modelid)\n",
    "    );\n",
    "    \"\"\",\n",
    "    \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS users (\n",
    "        email text,\n",
    "        partner text,\n",
    "        userid uuid,\n",
    "        firstname text,\n",
    "        lastname text,\n",
    "        role text,\n",
    "        PRIMARY KEY ((email, partner), userid)\n",
    "    );\n",
    "    \"\"\"\n",
    "]\n",
    "\n",
    "for query in table_queries:\n",
    "    session.execute(query)\n",
    "\n",
    "print(\"Keyspace and tables created successfully.\")\n",
    "rows = session.execute(f\"SELECT table_name FROM system_schema.tables WHERE keyspace_name='{KEYSPACE}';\")\n",
    "for row in rows:\n",
    "    print(\"Table:\", row.table_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, ToolMessage, SystemMessage, FunctionMessage, trim_messages, AIMessageChunk\n",
    "from pydantic import BaseModel, Field\n",
    "from copy import deepcopy\n",
    "\n",
    "from typing import Sequence\n",
    "\n",
    "class InMemoryHistory(BaseChatMessageHistory, BaseModel):\n",
    "    messages: list[BaseMessage] = Field(default_factory=list)\n",
    "\n",
    "    def add_messages(self, messages: Sequence[BaseMessage]) -> None:\n",
    "        self.messages.extend(messages)\n",
    "\n",
    "    def clear(self) -> None:\n",
    "        self.messages = []\n",
    "    \n",
    "    def edit_message_at_index(self, index: int, new_message: BaseMessage) -> None:\n",
    "        if 0 <= index < len(self.messages):\n",
    "            self.messages[index] = new_message\n",
    "            # Truncate all messages after the edited one\n",
    "            self.messages = self.messages[:index + 1]\n",
    "        else:\n",
    "            raise IndexError(\"Message index out of range.\")\n",
    "\n",
    "store = {}\n",
    "branch = \"main\"\n",
    "\n",
    "\n",
    "def get_chat_history_by_branch(branch: str) -> BaseChatMessageHistory:\n",
    "    if branch not in store:\n",
    "        store[branch] = InMemoryHistory()\n",
    "    return store[branch]\n",
    "\n",
    "\n",
    "def append_message_to_branch(message: BaseMessage, branch: str) -> None:\n",
    "    if branch not in store:\n",
    "        store[branch] = InMemoryHistory()\n",
    "    store[branch].messages.append(message)\n",
    "\n",
    "def create_branch_from(parent_branch: str, new_branch: str, edit_index: int, new_message: BaseMessage):\n",
    "    parent_history = store.get(parent_branch)\n",
    "    if not parent_history:\n",
    "        raise ValueError(f\"Parent branch '{parent_branch}' does not exist.\")\n",
    "\n",
    "    # Clone messages up to the edit point\n",
    "    new_history = InMemoryHistory(messages=deepcopy(parent_history.messages[:edit_index]))\n",
    "    # Add the new edited message\n",
    "    new_history.add_messages([new_message])\n",
    "    # Store the new branch\n",
    "    store[new_branch] = new_history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "parser = StrOutputParser()\n",
    "llm = AzureChatOpenAI(\n",
    "    azure_endpoint=os.environ[\"AZURE_OPENAI_ENDPOINT\"],\n",
    "    azure_deployment=os.environ[\"AZURE_OPENAI_DEPLOYMENT_NAME\"],\n",
    "    api_version=os.environ[\"AZURE_OPENAI_API_VERSION\"],\n",
    "    temperature=0.01,\n",
    "    stream_usage=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def process_input(input):\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"You are a helpful bot\"),\n",
    "        MessagesPlaceholder(variable_name=\"history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ])\n",
    "    chain = prompt | llm\n",
    "    chain_with_history = RunnableWithMessageHistory(\n",
    "        chain,\n",
    "        get_session_history=get_chat_history_by_branch,\n",
    "        input_messages_key=\"input\",\n",
    "        history_messages_key=\"history\",\n",
    "        history_factory_config=[\n",
    "            ConfigurableFieldSpec(\n",
    "                id=\"branch\",\n",
    "                annotation=str,\n",
    "                name=\"Chat Branch Name\",\n",
    "                description=\"Unique name for the chat branch\",\n",
    "                default=\"\",\n",
    "                is_shared=True,\n",
    "            ),\n",
    "        ],\n",
    "    )\n",
    "    # ai_message =\"\"\n",
    "    async for chunk in chain_with_history.astream({\"input\": input},\n",
    "                                                  config={\"configurable\": {\"branch\": branch}}):\n",
    "        print(chunk.content, end=\"\", flush=True)\n",
    "        # ai_message += chunk\n",
    "    # InMemoryHistory().add_messages([HumanMessage(content=input), AIMessage(content=ai_message)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "branch=\"part\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await process_input(HumanMessage(content=\"number 4 in french\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "# Create a new branch 'feature' by editing message at index 2 ('c') to 'g'\n",
    "create_branch_from(\n",
    "    parent_branch='main',\n",
    "    new_branch='b',\n",
    "    edit_index=0,\n",
    "    new_message=HumanMessage(content=\"check\")\n",
    ")\n",
    "\n",
    "# Add a new message 'j' to the 'feature' branch\n",
    "store['b'].add_messages([AIMessage(content=\"j\")])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cassandra to Postgres Migration Script**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Migrated users\n",
      "✔ Migrated chat history\n",
      "✔ Migrated models\n",
      "✔ Migrated subscriptions\n"
     ]
    }
   ],
   "source": [
    "from cassandra.cluster import Cluster\n",
    "import psycopg2\n",
    "import uuid\n",
    "import sys\n",
    "\n",
    "# Cassandra config\n",
    "CASSANDRA_KEYSPACE = \"eva\"\n",
    "CASSANDRA_CONTACT_POINTS = ['localhost']  # update as needed\n",
    "\n",
    "# Postgres config\n",
    "POSTGRES_CONN_PARAMS = {\n",
    "    'host': 'localhost',\n",
    "    'database': 'postgres',\n",
    "    'user': 'dev_user',\n",
    "    'password': 'dev_password',\n",
    "    'port': 5432\n",
    "}\n",
    "\n",
    "def connect_cassandra():\n",
    "    cluster = Cluster(CASSANDRA_CONTACT_POINTS)\n",
    "    session = cluster.connect()\n",
    "    session.set_keyspace(CASSANDRA_KEYSPACE)\n",
    "    return session\n",
    "\n",
    "def connect_postgres():\n",
    "    conn = psycopg2.connect(**POSTGRES_CONN_PARAMS)\n",
    "    conn.autocommit = True\n",
    "    return conn\n",
    "\n",
    "def migrate_users(cassandra_session, pg_conn):\n",
    "    rows = cassandra_session.execute(\"SELECT * FROM users\")\n",
    "    cur = pg_conn.cursor()\n",
    "    \n",
    "    for row in rows:\n",
    "        try:\n",
    "            cur.execute(\"\"\"\n",
    "                INSERT INTO public.users (user_id, email, partner, first_name, last_name, role)\n",
    "                VALUES (%s, %s, %s, %s, %s, %s)\n",
    "                ON CONFLICT (email, partner) DO NOTHING;\n",
    "            \"\"\", (\n",
    "                row.userid,\n",
    "                row.email,\n",
    "                row.partner,\n",
    "                row.firstname,\n",
    "                row.lastname,\n",
    "                row.role or 'user'\n",
    "            ))\n",
    "        except Exception as e:\n",
    "            print(f\"Error inserting user {row.email}: {e}\")\n",
    "    cur.close()\n",
    "    print(\"✔ Migrated users\")\n",
    "\n",
    "def migrate_chathistory(cassandra_session, pg_conn):\n",
    "    rows = cassandra_session.execute(\"SELECT * FROM chathistory\")\n",
    "    cur = pg_conn.cursor()\n",
    "\n",
    "    for row in rows:\n",
    "        try:\n",
    "            cur.execute(\"\"\"\n",
    "                INSERT INTO public.chat_history (chat_id, user_id, visible, history_blob, chat_title, last_updated, token_count)\n",
    "                VALUES (%s, %s, %s, %s, %s, %s, %s)\n",
    "                ON CONFLICT (chat_id) DO NOTHING;\n",
    "            \"\"\", (\n",
    "                row.chatid,\n",
    "                row.userid,\n",
    "                row.visible if row.visible is not None else True,\n",
    "                bytes(row.chathistoryjson),\n",
    "                row.chattitle,\n",
    "                row.createdon,\n",
    "                row.nettokenconsumption or 0\n",
    "            ))\n",
    "        except Exception as e:\n",
    "            print(f\"Error inserting chat {row.chatid}: {e}\")\n",
    "    cur.close()\n",
    "    print(\"✔ Migrated chat history\")\n",
    "\n",
    "def migrate_availablemodels(cassandra_session, pg_conn):\n",
    "    rows = cassandra_session.execute(\"SELECT * FROM availablemodels\")\n",
    "    cur = pg_conn.cursor()\n",
    "\n",
    "    for row in rows:\n",
    "        try:\n",
    "            cur.execute(\"\"\"\n",
    "                INSERT INTO public.ai_models (\n",
    "                    model_id, is_active, api_key, deployment_name, endpoint,\n",
    "                    model_name, model_type, model_version, provider\n",
    "                )\n",
    "                VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "                ON CONFLICT (deployment_name, model_version) DO NOTHING;\n",
    "            \"\"\", (\n",
    "                row.deploymentid,\n",
    "                row.isactive if row.isactive is not None else True,\n",
    "                row.apikey,\n",
    "                row.deploymentname,\n",
    "                row.endpoint,\n",
    "                row.modelname,\n",
    "                row.modeltype,\n",
    "                row.modelversion,\n",
    "                row.provider\n",
    "            ))\n",
    "        except Exception as e:\n",
    "            print(f\"Error inserting model {row.deploymentname}: {e}\")\n",
    "    cur.close()\n",
    "    print(\"✔ Migrated models\")\n",
    "\n",
    "def migrate_usersubscriptions(cassandra_session, pg_conn):\n",
    "    rows = cassandra_session.execute(\"SELECT * FROM usersubscriptions\")\n",
    "    cur = pg_conn.cursor()\n",
    "\n",
    "    for row in rows:\n",
    "        try:\n",
    "            cur.execute(\"\"\"\n",
    "                INSERT INTO public.subscriptions (sub_id, user_id, model_id)\n",
    "                VALUES (%s, %s, %s)\n",
    "                ON CONFLICT (user_id, model_id) DO NOTHING;\n",
    "            \"\"\", (\n",
    "                uuid.uuid4(),  # generating a new sub_id\n",
    "                row.userid,\n",
    "                row.modelid\n",
    "            ))\n",
    "        except Exception as e:\n",
    "            print(f\"Error inserting subscription for user {row.userid}: {e}\")\n",
    "    cur.close()\n",
    "    print(\"✔ Migrated subscriptions\")\n",
    "\n",
    "def main():\n",
    "    cassandra_session = connect_cassandra()\n",
    "    pg_conn = connect_postgres()\n",
    "    import psycopg2.extras\n",
    "    psycopg2.extras.register_uuid()\n",
    "    try:\n",
    "        migrate_users(cassandra_session, pg_conn)\n",
    "        migrate_chathistory(cassandra_session, pg_conn)\n",
    "        migrate_availablemodels(cassandra_session, pg_conn)\n",
    "        migrate_usersubscriptions(cassandra_session, pg_conn)\n",
    "    finally:\n",
    "        pg_conn.close()\n",
    "        cassandra_session.shutdown()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
